{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter15.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmnv6bMCsXis",
        "colab_type": "code",
        "outputId": "93591835-f0dc-4c54-82ac-966ac6cca2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPBKPav-sOyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxkUpF5wsoK0",
        "colab_type": "code",
        "outputId": "36b5bfb2-6527-4bb2-be92-5010933937be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzKNjxFFeNuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recurrent Neurons and Layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSkj9UC1lO0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output types\n",
        "#(seq to seq: gives a sequence of outputs)\n",
        "#(seq to vec: gives 1 output from the last cell, ignores the rest)\n",
        "#(vec to seq: a sequence from 1 input vector)\n",
        "#(encoder to decoder: sequence to vector to sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEnXIOp4mKEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training RNN\n",
        "#(BPTT: backprop through time: unroll the network and backprop like normal)\n",
        "#(the gradients flow through all outputs, hough some output mght be ignored)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jrv5kTjoTtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Time Series Forecasting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5tlSaymsAXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example time series\n",
        "def generate_time_series(batch_size, n_steps):\n",
        "  freq1, freq2, offset1, offset2 = np.random.rand(4, batch_size, 1)\n",
        "  time = np.linspace(0, 1, n_steps)\n",
        "  series = 0.5*np.sin((time-offset1) * (freq1*10 + 10))\n",
        "  series += 0.2*np.sin((time-offset2) * (freq2*20 + 20))\n",
        "  series += 0.1*(np.random.rand(batch_size, n_steps)-0.5)\n",
        "  return series[..., np.newaxis].astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jePx-ZoLtTcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps=50\n",
        "series = generate_time_series(10000, n_steps+1)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
        "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiHxFvdWy8ze",
        "colab_type": "code",
        "outputId": "87627017-fff5-48c8-998e-ba4fe920cbd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Benchmark\n",
        "#(using naive forecasting)\n",
        "y_pred = X_valid[:, -1]\n",
        "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.020888668"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKB15cJm2vDX",
        "colab_type": "code",
        "outputId": "2abd590f-65d0-46e7-bc5b-31b87bf11ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "source": [
        "#(using a simple linear regression net)\n",
        "model = keras.models.Sequential([\n",
        "                                keras.layers.Flatten(input_shape=[50, 1]),\n",
        "                                keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=keras.losses.mean_squared_error, optimizer=\"adam\")\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            "7000/7000 [==============================] - 2s 352us/sample - loss: 0.0670 - val_loss: 0.0309\n",
            "Epoch 2/20\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.0221 - val_loss: 0.0165\n",
            "Epoch 3/20\n",
            "7000/7000 [==============================] - 1s 83us/sample - loss: 0.0138 - val_loss: 0.0122\n",
            "Epoch 4/20\n",
            "7000/7000 [==============================] - 1s 80us/sample - loss: 0.0108 - val_loss: 0.0101\n",
            "Epoch 5/20\n",
            "7000/7000 [==============================] - 1s 81us/sample - loss: 0.0091 - val_loss: 0.0085\n",
            "Epoch 6/20\n",
            "7000/7000 [==============================] - 1s 79us/sample - loss: 0.0078 - val_loss: 0.0073\n",
            "Epoch 7/20\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.0068 - val_loss: 0.0064\n",
            "Epoch 8/20\n",
            "7000/7000 [==============================] - 1s 85us/sample - loss: 0.0061 - val_loss: 0.0058\n",
            "Epoch 9/20\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.0054 - val_loss: 0.0052\n",
            "Epoch 10/20\n",
            "7000/7000 [==============================] - 1s 84us/sample - loss: 0.0050 - val_loss: 0.0048\n",
            "Epoch 11/20\n",
            "7000/7000 [==============================] - 1s 81us/sample - loss: 0.0047 - val_loss: 0.0045\n",
            "Epoch 12/20\n",
            "7000/7000 [==============================] - 1s 82us/sample - loss: 0.0045 - val_loss: 0.0043\n",
            "Epoch 13/20\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 14/20\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.0042 - val_loss: 0.0040\n",
            "Epoch 15/20\n",
            "7000/7000 [==============================] - 1s 79us/sample - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 16/20\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.0040 - val_loss: 0.0038\n",
            "Epoch 17/20\n",
            "7000/7000 [==============================] - 1s 80us/sample - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 18/20\n",
            "7000/7000 [==============================] - 1s 79us/sample - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 19/20\n",
            "7000/7000 [==============================] - 1s 82us/sample - loss: 0.0038 - val_loss: 0.0036\n",
            "Epoch 20/20\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.0037 - val_loss: 0.0035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0923755f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6ZOBh-T3hRh",
        "colab_type": "code",
        "outputId": "f4392ba7-1fc4-4e33-850b-5d10759a98ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0035688097048550845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjgmo3GX3ylJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-hvaYCI4PQb",
        "colab_type": "code",
        "outputId": "f0f883e9-f5d4-48d3-9756-2b57ee0cf5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Simple RNN\n",
        "model = Sequential([ \n",
        "                    SimpleRNN(1, input_shape=[None, 1])\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0921b76a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk46LOrF48Ci",
        "colab_type": "code",
        "outputId": "130ed7b7-de94-4ed8-9a11-93c96fd8f90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model.evaluate(X_valid, y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 158us/sample - loss: 0.1420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14203766334056855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnm4uAf-5bln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep RNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDL61_XkCIm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([ \n",
        "                    SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "                    SimpleRNN(20),\n",
        "                    Dense(1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7wUVgL7CWpY",
        "colab_type": "code",
        "outputId": "17d5c8e1-6ce6-4245-f47a-edacf53810ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0249 - val_loss: 0.0042\n",
            "Epoch 2/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0038 - val_loss: 0.0036\n",
            "Epoch 3/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 4/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 5/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 6/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0031 - val_loss: 0.0028\n",
            "Epoch 7/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0031 - val_loss: 0.0033\n",
            "Epoch 8/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 9/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 10/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 11/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 12/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 13/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 14/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 15/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 16/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 17/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0029 - val_loss: 0.0026\n",
            "Epoch 18/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 19/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 20/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0028 - val_loss: 0.0026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff07893b588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGL2v6hZCmT4",
        "colab_type": "code",
        "outputId": "5c1e86bd-0360-42ef-ac24-b0f6f946ceff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model.evaluate(X_valid, y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 1s 281us/sample - loss: 0.0026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002605174858123064"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYXxRHxrEKxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Forecasting several steps ahead\n",
        "#(use the old model, keeps predicting with the predicted values)\n",
        "series = generate_time_series(1, n_steps+10)\n",
        "X_new, y_new = series[:, :n_steps], series[:, n_steps:]\n",
        "X = X_new\n",
        "for step_ahead in range(10):\n",
        "  y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
        "  X = np.concatenate([X, y_pred_one], axis=1)\n",
        "y_pred = X[:, n_steps:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2huQ4_hLEHK",
        "colab_type": "code",
        "outputId": "fc2399ec-a353-4cef-876b-31780d897079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "source": [
        "#(predicting a vector of 10 all at once)\n",
        "#(requiring trnasforming the targets to be vectors of 10)\n",
        "series = generate_time_series(10000, n_steps+10)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
        "X_test, y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
        "\n",
        "model = Sequential([ \n",
        "                    SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "                    SimpleRNN(20),\n",
        "                    Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "\n",
        "y_pred = model.predict(X_new)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0726 - val_loss: 0.0321\n",
            "Epoch 2/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0237 - val_loss: 0.0185\n",
            "Epoch 3/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0161 - val_loss: 0.0184\n",
            "Epoch 4/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0135 - val_loss: 0.0123\n",
            "Epoch 5/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0118 - val_loss: 0.0115\n",
            "Epoch 6/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0114 - val_loss: 0.0113\n",
            "Epoch 7/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0108 - val_loss: 0.0102\n",
            "Epoch 8/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0105 - val_loss: 0.0104\n",
            "Epoch 9/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0105 - val_loss: 0.0104\n",
            "Epoch 10/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0106 - val_loss: 0.0098\n",
            "Epoch 11/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0100 - val_loss: 0.0096\n",
            "Epoch 12/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0097 - val_loss: 0.0097\n",
            "Epoch 13/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0096 - val_loss: 0.0093\n",
            "Epoch 14/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0093 - val_loss: 0.0090\n",
            "Epoch 15/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0094 - val_loss: 0.0101\n",
            "Epoch 16/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0093 - val_loss: 0.0091\n",
            "Epoch 17/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0091 - val_loss: 0.0087\n",
            "Epoch 18/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0090 - val_loss: 0.0094\n",
            "Epoch 19/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0090 - val_loss: 0.0093\n",
            "Epoch 20/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0087 - val_loss: 0.0088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbKblYBuPknK",
        "colab_type": "code",
        "outputId": "3c63f2bd-88ce-45f9-f2e7-f3fe2dafb4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "#(seq to seq approach: forecasts next 10 steps at every step)\n",
        "#(more error gradients to train)\n",
        "n_steps=50\n",
        "series=generate_time_series(10000, n_steps+10)\n",
        "X_train = series[:7000, :n_steps]\n",
        "X_valid = series[7000:9000, :n_steps]\n",
        "X_test = series[9000:, :n_steps]\n",
        "y = np.empty((10000, n_steps, 10))   # target becomes a 10D vectors\n",
        "for step_ahead in range(1, 10+1):\n",
        "  y[:, :, step_ahead-1] = series[:, step_ahead:step_ahead+n_steps, 0]\n",
        "y_train = y[:7000]\n",
        "y_valid = y[7000:9000]\n",
        "y_test = y[9000:]\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "model = Sequential([ \n",
        "                    SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "                    SimpleRNN(20, return_sequences=True),\n",
        "                    TimeDistributed(Dense(10))   #timedis is a wrapper that applies the wrapped layer at every step of the seq\n",
        "])\n",
        "\n",
        "#(the above will have every outputs calculated in metric, while only the last one is important)\n",
        "def last_time_step_mse(y_true, y_pred):\n",
        "  return keras.metrics.mean_squared_error(y_true[:, -1], y_pred[:, -1])\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "              optimizer=keras.optimizers.Adam(lr=0.01),\n",
        "              metrics=[last_time_step_mse])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0472 - last_time_step_mse: 0.0358 - val_loss: 0.0380 - val_last_time_step_mse: 0.0223\n",
            "Epoch 2/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0346 - last_time_step_mse: 0.0225 - val_loss: 0.0295 - val_last_time_step_mse: 0.0162\n",
            "Epoch 3/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0299 - last_time_step_mse: 0.0178 - val_loss: 0.0298 - val_last_time_step_mse: 0.0179\n",
            "Epoch 4/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0276 - last_time_step_mse: 0.0161 - val_loss: 0.0260 - val_last_time_step_mse: 0.0145\n",
            "Epoch 5/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0258 - last_time_step_mse: 0.0140 - val_loss: 0.0256 - val_last_time_step_mse: 0.0135\n",
            "Epoch 6/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0244 - last_time_step_mse: 0.0126 - val_loss: 0.0241 - val_last_time_step_mse: 0.0118\n",
            "Epoch 7/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0224 - last_time_step_mse: 0.0104 - val_loss: 0.0218 - val_last_time_step_mse: 0.0101\n",
            "Epoch 8/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0212 - last_time_step_mse: 0.0092 - val_loss: 0.0213 - val_last_time_step_mse: 0.0092\n",
            "Epoch 9/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0206 - last_time_step_mse: 0.0087 - val_loss: 0.0225 - val_last_time_step_mse: 0.0110\n",
            "Epoch 10/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0201 - last_time_step_mse: 0.0084 - val_loss: 0.0203 - val_last_time_step_mse: 0.0081\n",
            "Epoch 11/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0197 - last_time_step_mse: 0.0080 - val_loss: 0.0198 - val_last_time_step_mse: 0.0084\n",
            "Epoch 12/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0190 - last_time_step_mse: 0.0072 - val_loss: 0.0192 - val_last_time_step_mse: 0.0071\n",
            "Epoch 13/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0188 - last_time_step_mse: 0.0072 - val_loss: 0.0193 - val_last_time_step_mse: 0.0076\n",
            "Epoch 14/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0185 - last_time_step_mse: 0.0069 - val_loss: 0.0187 - val_last_time_step_mse: 0.0066\n",
            "Epoch 15/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0180 - last_time_step_mse: 0.0064 - val_loss: 0.0178 - val_last_time_step_mse: 0.0060\n",
            "Epoch 16/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0179 - last_time_step_mse: 0.0063 - val_loss: 0.0199 - val_last_time_step_mse: 0.0083\n",
            "Epoch 17/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0179 - last_time_step_mse: 0.0065 - val_loss: 0.0177 - val_last_time_step_mse: 0.0055\n",
            "Epoch 18/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0179 - last_time_step_mse: 0.0065 - val_loss: 0.0176 - val_last_time_step_mse: 0.0056\n",
            "Epoch 19/20\n",
            "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0176 - last_time_step_mse: 0.0063 - val_loss: 0.0172 - val_last_time_step_mse: 0.0052\n",
            "Epoch 20/20\n",
            "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0179 - last_time_step_mse: 0.0065 - val_loss: 0.0187 - val_last_time_step_mse: 0.0072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BeZi36uZ8Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(for error bars seen in time series forecasting, use MC Dropout to get mean and std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPtxFSNdbJOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Handling Long Sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2WBulKTbMUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unstable gradients\n",
        "#(techinques like good initializer, faster optimizers, dropout still work, non-saturating activation functions dont)\n",
        "#(non-saturating is bad because gradients get multiplied further down the time steps, leads to exploding gradients)\n",
        "#(as such, saturating functions like tanh are better, or maybe use gradient clipping)\n",
        "#(batch norm also doesnt work, since it will use the same scaling and offset on both hidden states and inputs, using it on inputs alone provide minimal pmprovement)\n",
        "#(instead, use layer normalization, which also normalized, but mean and std are calculated feature-wise (instead of sample/batch wise))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q3T7MrDwAks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add layer normalization to a RNN cell\n",
        "class LNSimpleRNNCell(keras.layers.Layer):\n",
        "  def __init__(self, units, activation=\"tanh\", **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.state_size = units\n",
        "    self.output_size = units\n",
        "    self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)\n",
        "    self.layer_norm = keras.layers.LayerNormalization()\n",
        "    self.activation = keras.activations.get(activation)\n",
        "  def call(self, inputs, states):\n",
        "    outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
        "    norm_outputs = self.activation(self.layer_norm(outputs))\n",
        "    return norm_outputs, [norm_outputs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtBRZuMnx96r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import RNN, TimeDistributed, Dense\n",
        "\n",
        "model = Sequential([ \n",
        "                    RNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),\n",
        "                    RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
        "                    TimeDistributed(Dense(10))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icse0ElWz0tH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "d72409bb-3bcc-49e0-8fbd-b11e94f965e0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rnn_2 (RNN)                  (None, None, 20)          480       \n",
            "_________________________________________________________________\n",
            "rnn_3 (RNN)                  (None, None, 20)          860       \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 10)          210       \n",
            "=================================================================\n",
            "Total params: 1,550\n",
            "Trainable params: 1,550\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbiWCpe1z4RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Short term memory problem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHegISH865UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM cell\n",
        "#(the state is split into 2 vectors, short-term and long-term, short term also acts as the output)\n",
        "#(a main layer that takes the input and previous state)\n",
        "#(a forget gate layer that drops parts of the long-term state (a log function output 0-1, multiply element wise))\n",
        "#(an input gate layer that adds to the long-term state)\n",
        "#(an output gate that outputs state and output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHsO7D5UFsww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM in keras\n",
        "# Using lstm layer (optimized)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, LSTMCell, TimeDistributed, Dense, RNN\n",
        "\n",
        "model = Sequential([ \n",
        "                    LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
        "                    LSTM(20, return_sequences=True),\n",
        "                    TimeDistributed(Dense(10))\n",
        "])\n",
        "\n",
        "# Alternatively use RNN leyer with lstmcell arg (for custom cell)\n",
        "model = Sequential([ \n",
        "                    RNN(LSTMCell(20), return_sequences=True, input_shape=[None, 1]),\n",
        "                    RNN(LSTMCell(20), return_sequences=True),\n",
        "                    TimeDistributed(Dense(10))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RFsx8hoI8m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Peephole connections\n",
        "#(let the gates look at the long term state as well)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_qjhYeKJuFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRU cell\n",
        "#(a peephole variant)\n",
        "#(both states are in 1 output vector)\n",
        "#(1 gate do both forgetting and adding, so only forgetting ·ªè adding one at a time)\n",
        "#(a seperate gate controls the previous state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdEjt6rdz2K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1D conv layers\n",
        "model = Sequential([ \n",
        "                    Conv1D(filters=20, kernel_size=4, strides=2, padding=\"VALID\", input_shape=[None, 1]),\n",
        "                    GRU(20, return_sequences=True),\n",
        "                    GRU(20, return_sequences=True),\n",
        "                    TimeDistributed(Dense(10))\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
        "history = model.fit(X_train, y_train[:, 3::2], epochs=20,\n",
        "                    validation_data=(X_valid, y_valid[:, 3::2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZRnuoYD01UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WaveNet\n",
        "#(stacks of 1D conv layers with kernel size of 2)\n",
        "#(doubling dilation rate at every layer)\n",
        "model = Sequential([ \n",
        "                    InputLayer(input_shape=[None, 1])\n",
        "])\n",
        "for rate in (1, 2, 4, 8)*2:\n",
        "  model.add(Conv1D(filters=20, kernel_size=2, padding=\"CAUSAL\", activation=\"relu\", dilation_rate=rate))\n",
        "model.add(Conv1D(filters=10, kernel_size=1))\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}