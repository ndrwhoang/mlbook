{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fewer parameters, feature invariance, learn image feature hierarchy better due to desgin(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Number of parameters ((kernel*inputs dimensions+bias)*filters): \n",
    "#((3*3*3+1)*100) + ((3*3*100+1)*200) + ((3*3*200+1)*400)\n",
    "# RAM usage of 1 sample: (feature maps size*4 bytes) + (memory for parameters)\n",
    "#(100*150*4) + (50*75*4) + (25*38*4) + above\n",
    "# RAM usage of mini batch of 50: (for filters + for image input)*50 + (for weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Decrease batch size, scale down image, scale down architecture, optimize code, distributing compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Max pooling doesnt take memory, easier to compute, removes some variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Local response normalization makes different filters learn different things to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. \n",
    "#AlexNet: larger, deeper than lenet, uses dropout, and data augmentation\n",
    "#GooLeNet: uses Inception cell to learn more patterns and depth information\n",
    "#VGGNet: stacks of (2-3 conv with many 3x3 filters and 1 pooling)\n",
    "#ResNet: has skip connections \n",
    "#Xception: replaces inception cell with a cell of (1 stack of conv for spatial patterns to 1 stack of 1x1 conv for cross-channel patterns)\n",
    "#SENet: adds a small neural net to every inception/residual module, the neural net will learn to boost some signals (see strong mouth and strong nose -> boost weak eyes signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. A neural net with only conv layers. Convert dense layer to a conv with kernel size same as the last conv and same number of filters as required dense neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Difficulty in losing information from conv layers while requiring pixel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
